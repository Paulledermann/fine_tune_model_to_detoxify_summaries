Fine-Tune FLAN-T5 for Less-Toxic Summaries

This lab explores fine-tuning a FLAN-T5 model using Reinforcement Learning (PPO) and Parameter Efficient Fine-Tuning (PEFT) to generate less toxic summaries. I used Meta AIâ€™s hate speech reward model, which classifies text as "hate" or "not hate," to guide the model's behavior.
